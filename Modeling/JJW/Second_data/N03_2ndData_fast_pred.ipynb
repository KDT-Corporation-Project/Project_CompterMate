{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빠르게 1차 데이터 전처리 방식대로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38689, 12) (1405, 6) (37244, 6)\n",
      "Index(['time', 'E_scr_pv', 'E_scr_sv', 'c_temp_pv', 'c_temp_sv', 'k_rpm_pv',\n",
      "       'k_rpm_sv', 'n_temp_pv', 'n_temp_sv', 'scale_pv', 's_temp_pv',\n",
      "       's_temp_sv'],\n",
      "      dtype='object')\n",
      "Index(['E_scr_pv', 'c_temp_pv', 'k_rpm_pv', 'n_temp_pv', 'scale_pv',\n",
      "       's_temp_pv'],\n",
      "      dtype='object')\n",
      "Index(['E_scr_pv', 'c_temp_pv', 'k_rpm_pv', 'n_temp_pv', 'scale_pv',\n",
      "       's_temp_pv'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\AppData\\Local\\Temp\\ipykernel_4684\\1947819165.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['time'] = pd.to_datetime(data['time'])\n",
      "C:\\Users\\HOME\\AppData\\Local\\Temp\\ipykernel_4684\\1947819165.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oct_data.drop('time', axis=1, inplace=True)\n",
      "C:\\Users\\HOME\\AppData\\Local\\Temp\\ipykernel_4684\\1947819165.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.drop('time', axis=1, inplace=True)\n",
      "C:\\Users\\HOME\\AppData\\Local\\Temp\\ipykernel_4684\\1947819165.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oct_data.drop(['E_scr_sv', 'c_temp_sv', 'n_temp_sv', 's_temp_sv', 'k_rpm_sv'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing : 1st 분석 결과\n",
    "data = pd.read_csv('../DATA/raw_2023051820231018_경대기업맞춤형.csv')\n",
    "\n",
    "def prep_1st(data, SCALE=True, UNNAMED=True):\n",
    "    # 1) 2차 데이터에서 필요한 전처리\n",
    "    if UNNAMED:     # Unnamed: 12 컬럼 제거\n",
    "        data.drop('Unnamed: 12', axis=1, inplace=True)  # Unnamed: 12 컬럼 제거\n",
    "        \n",
    "    data['k_rpm_pv'] = data['k_rpm_pv'].apply(lambda x: x/10 if x > 1000 else x)        # k_rpm_pv가 1000이상이면 1/10\n",
    "\n",
    "    # 2) 결측치 제거\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # 3) 2 < scale_pv < 4 이외 데이터 제거\n",
    "    if SCALE:   # 증강 시 False\n",
    "        data = data[(data['scale_pv'] > 2) & (data['scale_pv'] < 4)]\n",
    "\n",
    "    # 4) oct_data, train_data 분리\n",
    "    data['time'] = pd.to_datetime(data['time'])\n",
    "    oct_data = data[data['time'].dt.month == 10]\n",
    "    train_data = data[data['time'].dt.month != 10]\n",
    "    oct_data.drop('time', axis=1, inplace=True)\n",
    "    train_data.drop('time', axis=1, inplace=True)\n",
    "\n",
    "    # [train_data] ===============================================\n",
    "    # 5) n_temp_sv == 0 제거\n",
    "    train_data = train_data[train_data['n_temp_sv'] != 0]\n",
    "\n",
    "    # 6) 100 < k_rpm_pv\n",
    "    train_data = train_data[train_data['k_rpm_pv'] > 100]\n",
    "    # ============================================================\n",
    "\n",
    "    # 7) E_scr_sv, c_temp_sv, n_temp_sv, s_temp_sv, k_rpm_sv 제거\n",
    "    train_data.drop(['E_scr_sv', 'c_temp_sv', 'n_temp_sv', 's_temp_sv', 'k_rpm_sv'], axis=1, inplace=True)\n",
    "    oct_data.drop(['E_scr_sv', 'c_temp_sv', 'n_temp_sv', 's_temp_sv', 'k_rpm_sv'], axis=1, inplace=True)\n",
    "\n",
    "    return data, oct_data, train_data\n",
    "\n",
    "data, oct_data, train_data = prep_1st(data)\n",
    "\n",
    "# Check Data shape\n",
    "print(data.shape, oct_data.shape, train_data.shape)\n",
    "# - 38,689 / 1,405 / 37,244\n",
    "print(data.columns)\n",
    "print(oct_data.columns)\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 증강 없이 학습 & 예측\n",
    "1. Oct_data : scale만 조정한 10월 데이터\n",
    "2. train_data : scale, k_rpm_pv만 조정한 10월 이전 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 0.020272394975119748\n",
      "MAPE : 0.6666726546205615\n",
      "R2 : 0.43103843507959383\n",
      "MAE : 0.027518967236401404\n",
      "MAPE : 0.9009062643498273\n",
      "R2 : -0.2779995790738863\n"
     ]
    }
   ],
   "source": [
    "# 증강 없이 학습\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "X = train_data.drop('scale_pv', axis=1)\n",
    "y = train_data['scale_pv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'min_samples_split': [2, 5],\n",
    "#     'min_samples_leaf': [1, 2]\n",
    "# }\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1, verbose=3, scoring='neg_mean_absolute_error')\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "# rf = grid_search.best_estimator_\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('MAE :', mean_absolute_error(y_test, y_pred))\n",
    "print('MAPE :', mean_absolute_percentage_error(y_test, y_pred)*100)\n",
    "print('R2 :', r2_score(y_test, y_pred))\n",
    "\n",
    "# 증강 없이 예측\n",
    "X_oct = oct_data.drop('scale_pv', axis=1)\n",
    "y_oct = oct_data['scale_pv']\n",
    "y_oct_pred = rf.predict(X_oct)\n",
    "\n",
    "print('MAE :', mean_absolute_error(y_oct, y_oct_pred))\n",
    "print('MAPE :', mean_absolute_percentage_error(y_oct, y_oct_pred)*100)\n",
    "print('R2 :', r2_score(y_oct, y_oct_pred))\n",
    "\n",
    "# - rf에서 criterion='absolute_error'로 설정하면 너무 오래걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중공선성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시명님의 증강 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 413. GiB for an array with shape (235413, 235413) and data type timedelta64[ns]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m mask_2to4 \u001b[38;5;241m=\u001b[39m DF1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale_pv\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 10초 이내의 이전 행들 중 scale_pv가 1 이하인 행을 찾기 위한 mask 생성\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m mask_10s \u001b[38;5;241m=\u001b[39m (\u001b[43mDF1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDF1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtimedelta64(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m mask_le1 \u001b[38;5;241m=\u001b[39m DF1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale_pv\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     36\u001b[0m mask_prev_le1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtril(mask_10s \u001b[38;5;241m&\u001b[39m mask_le1)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 413. GiB for an array with shape (235413, 235413) and data type timedelta64[ns]"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# DF1 = data.copy()\n",
    "\n",
    "# DF1['time'] = pd.to_datetime(DF1['time'])\n",
    "\n",
    "# for idx, row in DF1.iterrows():\n",
    "#     if 2 <= row['scale_pv'] <= 4:\n",
    "#         target_time6 = row['time'] - timedelta(seconds=10)\n",
    "#         mask = (DF1['time'] <= row['time']) & (DF1['time'] >= target_time6)\n",
    "#         previous_rows = DF1[mask]\n",
    "        \n",
    "#         if len(previous_rows) > 1:\n",
    "#             previous_row = previous_rows.iloc[-2]  # 조건을 만족하는 가장 마지막에서 두 번째 행\n",
    "#             if previous_row['scale_pv'] <= 1:\n",
    "#                 # 조건을 만족하는 모든 행의 scale_pv 값을 패딩\n",
    "#                 for i in range(len(previous_rows)):\n",
    "#                     if previous_rows.iloc[i]['scale_pv'] <= 1:\n",
    "#                         DF1.loc[previous_rows.index[i], 'scale_pv'] = row['scale_pv']\n",
    "# DF1_2to4 = DF1[DF1.scale_pv.between(2,4)]\n",
    "# DF1_2to4\n",
    "\n",
    "# gpt가 수정 ================================\n",
    "# data = pd.read_csv('../DATA/raw_2023051820231018_경대기업맞춤형.csv')\n",
    "\n",
    "# DF1 = data.copy()\n",
    "# DF1['time'] = pd.to_datetime(DF1['time'])\n",
    "# DF1 = DF1.sort_values('time')  # 시간 순으로 정렬\n",
    "\n",
    "# # scale_pv가 2에서 4 사이인지 아닌지에 대한 boolean mask 생성\n",
    "# mask_2to4 = DF1['scale_pv'].between(2, 4)\n",
    "\n",
    "# # 10초 이내의 이전 행들 중 scale_pv가 1 이하인 행을 찾기 위한 mask 생성\n",
    "# mask_10s = (DF1['time'].values - DF1['time'].values[:, None]) <= np.timedelta64(10, 's')\n",
    "# mask_le1 = DF1['scale_pv'].values <= 1\n",
    "# mask_prev_le1 = np.tril(mask_10s & mask_le1)\n",
    "\n",
    "# # scale_pv가 2에서 4 사이인 행의 이전 행들 중 scale_pv가 1 이하인 행을 찾아서 업데이트\n",
    "# for idx in np.where(mask_2to4)[0]:\n",
    "#     prev_rows = np.where(mask_prev_le1[idx])[0]\n",
    "#     if len(prev_rows) > 0:\n",
    "#         DF1.loc[DF1.index[prev_rows], 'scale_pv'] = DF1.loc[DF1.index[idx], 'scale_pv']\n",
    "\n",
    "# DF1_2to4 = DF1[mask_2to4]\n",
    "# DF1_2to4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 진행\n",
    "# data_2to4, oct_data_2to4, train_data_2to4 = prep_1st(DF1_2to4)\n",
    "\n",
    "# print(data_2to4.shape, oct_data_2to4.shape, train_data_2to4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 메모리 문제,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN 개수 : 163440\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# imputer\u001b[39;00m\n\u001b[0;32m     39\u001b[0m imputer \u001b[38;5;241m=\u001b[39m KNNImputer(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN 개수 :\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39misnan(y)\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# 증강된 데이터로 학습\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\impute\\_knn.py:365\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;66;03m# process in fixed-memory chunks\u001b[39;00m\n\u001b[0;32m    357\u001b[0m gen \u001b[38;5;241m=\u001b[39m pairwise_distances_chunked(\n\u001b[0;32m    358\u001b[0m     X[row_missing_idx, :],\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m     reduce_func\u001b[38;5;241m=\u001b[39mprocess_chunk,\n\u001b[0;32m    364\u001b[0m )\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m gen:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;66;03m# process_chunk modifies X in place. No return value.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_empty_features:\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2018\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2016\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2017\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2018\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2020\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2021\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2022\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2024\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2196\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2194\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1766\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1763\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1769\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:511\u001b[0m, in \u001b[0;36mnan_euclidean_distances\u001b[1;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[0;32m    509\u001b[0m present_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m missing_X\n\u001b[0;32m    510\u001b[0m present_Y \u001b[38;5;241m=\u001b[39m present_X \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m~\u001b[39mmissing_Y\n\u001b[1;32m--> 511\u001b[0m present_count \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpresent_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresent_Y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m distances[present_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# avoid divide by zero\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 증강하여 학습\n",
    "# - train_data의 1 미만인 값에서 KNN으로 증강\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "data = pd.read_csv('../DATA/raw_2023051820231018_경대기업맞춤형.csv')\n",
    "\n",
    "# 10월 이전 데이터만 사용\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "train_data = data[data['time'].dt.month != 10]\n",
    "oct_data = data[data['time'].dt.month == 10]\n",
    "\n",
    "# scale_pv < 4 데이터만 사용\n",
    "train_data = train_data[train_data['scale_pv'] < 4]\n",
    "\n",
    "# n_temp_sv == 0 제거\n",
    "train_data = train_data[train_data['n_temp_sv'] != 0]\n",
    "\n",
    "# 100 < k_rpm_pv\n",
    "train_data = train_data[train_data['k_rpm_pv'] > 100]\n",
    "\n",
    "# scale_pv < 2 => NaN\n",
    "train_data['scale_pv'] = train_data['scale_pv'].apply(lambda x: np.nan if x < 2 else x)\n",
    "print('NaN 개수 :', train_data['scale_pv'].isnull().sum())\n",
    "\n",
    "# drop columns\n",
    "train_data.drop(['Unnamed: 12', 'E_scr_sv', 'c_temp_sv', 'n_temp_sv', 's_temp_sv', 'k_rpm_sv', 'time'], axis=1, inplace=True)\n",
    "\n",
    "# KNN Imputer : target은 scale_pv, NaN은 2 미만인 값\n",
    "X = train_data.drop('scale_pv', axis=1)\n",
    "y = train_data['scale_pv']\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# y = imputer.fit_transform(y.values.reshape(-1, 1)).reshape(-1)\n",
    "print('NaN 개수 :', np.isnan(y).sum())\n",
    "\n",
    "# 증강된 데이터로 학습\n",
    "train_data['scale_pv'] = y\n",
    "\n",
    "X = train_data.drop('scale_pv', axis=1)\n",
    "y = train_data['scale_pv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('MAE :', mean_absolute_error(y_test, y_pred))\n",
    "print('MAPE :', mean_absolute_percentage_error(y_test, y_pred)*100)\n",
    "print('R2 :', r2_score(y_test, y_pred))\n",
    "\n",
    "# 증강된 데이터로 예측\n",
    "# - oct_data : 2 < scale_pv < 4\n",
    "oct_data = oct_data[(oct_data['scale_pv'] > 2) & (oct_data['scale_pv'] < 4)]\n",
    "oct_data.drop(['Unnamed: 12', 'E_scr_sv', 'c_temp_sv', 'n_temp_sv', 's_temp_sv', 'k_rpm_sv', 'time'], axis=1, inplace=True)\n",
    "\n",
    "X_oct = oct_data.drop('scale_pv', axis=1)\n",
    "y_oct = oct_data['scale_pv']\n",
    "y_oct_pred = rf.predict(X_oct)\n",
    "\n",
    "print('MAE :', mean_absolute_error(y_oct, y_oct_pred))\n",
    "print('MAPE :', mean_absolute_percentage_error(y_oct, y_oct_pred)*100)\n",
    "print('R2 :', r2_score(y_oct, y_oct_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN 증강에서 오류, 수정해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
